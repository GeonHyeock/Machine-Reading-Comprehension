_target_: src.models.roberta_module.RobertaModule

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001


scheduler:
  _target_: src.models.components.pytorch_cosine_annealing_with_warmup.cosine_annealing_warmup.scheduler.CosineAnnealingWarmupRestarts
  _partial_: true
  first_cycle_steps: 6826 
  cycle_mult: 1.0
  max_lr: 1e-5
  min_lr: 1e-8
  warmup_steps: 1826
  gamma: 0.995
  start_epoch: 3
  base_lr: 5e-5

scheduler_monitor:
  monitor: "train/loss"
  interval: "step"
  frequency: 1

net:
  _target_: src.models.components.roberta.Roberta
  name: "klue/roberta-large"
  hidden_state: 2560
  is_ensemble: True

# compile model for faster training with pytorch 2.0
compile: false
